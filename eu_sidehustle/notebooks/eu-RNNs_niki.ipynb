{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b4ee95-3e8a-4dfd-83e3-1ff8ebd408ca",
   "metadata": {},
   "source": [
    "# mini sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18dfce9-9679-4069-b48a-d24f610e4168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# macht mehrere sequences indem sie die funktion darunter called\n",
    "def get_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336d1838-c44f-480f-a25c-09b4db78c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# macht eine sequence\n",
    "def get Xi_yi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b35ce17-241e-4c98-ab46-bf6454be850a",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a222d6f8-0229-4239-b3fc-89dc68b4413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Data Visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# System\n",
    "import os\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5c69a9-c282-4e26-86cb-8813c9ef9e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1765783-af9b-45b6-8d2c-8c5789ac3d3f",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "225e25ec-e391-4d41-b11c-b7f677fa3111",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/niki/code/Niki827/watt_squad/eu_sidehustle/aggregating_preprocessing/data/04_preprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9c5bb41-67b2-40c3-8af3-1711cbf05b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "athens = pd.read_csv(f'{path}/Athens_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9b080d8-a397-4964-aadf-7b48d367ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin = pd.read_csv(f'{path}/Berlin_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed4643cc-7ce4-408a-b3cd-cbe55fd8c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "london = pd.read_csv(f'{path}/London_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdbc60eb-1f22-4124-ae28-369cfa452f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid = pd.read_csv(f'{path}/Madrid_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33d4e6b7-e240-4637-94af-a0763f231586",
   "metadata": {},
   "outputs": [],
   "source": [
    "paris = pd.read_csv(f'{path}/Paris_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f60d711-9109-411d-a85e-778ab857cbd2",
   "metadata": {},
   "source": [
    "## Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d092533e-685e-4d18-bb0a-c93555745003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pv_output</th>\n",
       "      <th>direct_irradiance</th>\n",
       "      <th>diffuse_irradiance</th>\n",
       "      <th>reflected_irradiance</th>\n",
       "      <th>sun_height</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>year_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.18438</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.065585</td>\n",
       "      <td>0.031635</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>0.365736</td>\n",
       "      <td>0.331266</td>\n",
       "      <td>1.721336e-02</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.55676</td>\n",
       "      <td>0.332888</td>\n",
       "      <td>0.188187</td>\n",
       "      <td>0.137603</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.318815</td>\n",
       "      <td>0.431817</td>\n",
       "      <td>3.442161e-02</td>\n",
       "      <td>0.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.25707</td>\n",
       "      <td>0.287603</td>\n",
       "      <td>0.181857</td>\n",
       "      <td>0.127422</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>0.290491</td>\n",
       "      <td>0.318518</td>\n",
       "      <td>5.161967e-02</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.77577</td>\n",
       "      <td>0.364820</td>\n",
       "      <td>0.198938</td>\n",
       "      <td>0.151992</td>\n",
       "      <td>0.010888</td>\n",
       "      <td>0.251810</td>\n",
       "      <td>0.337021</td>\n",
       "      <td>6.880243e-02</td>\n",
       "      <td>0.997630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.08309</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.033462</td>\n",
       "      <td>0.015843</td>\n",
       "      <td>0.012606</td>\n",
       "      <td>0.356150</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>8.596480e-02</td>\n",
       "      <td>0.996298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>2.03699</td>\n",
       "      <td>0.232890</td>\n",
       "      <td>0.227027</td>\n",
       "      <td>0.130902</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.391161</td>\n",
       "      <td>0.478298</td>\n",
       "      <td>-6.880243e-02</td>\n",
       "      <td>0.997630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>1.26006</td>\n",
       "      <td>0.150560</td>\n",
       "      <td>0.133012</td>\n",
       "      <td>0.083684</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.417086</td>\n",
       "      <td>0.548688</td>\n",
       "      <td>-5.161967e-02</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6936</th>\n",
       "      <td>0.43408</td>\n",
       "      <td>0.028270</td>\n",
       "      <td>0.108200</td>\n",
       "      <td>0.053192</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.401442</td>\n",
       "      <td>0.559403</td>\n",
       "      <td>-3.442161e-02</td>\n",
       "      <td>0.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>0.28637</td>\n",
       "      <td>0.009971</td>\n",
       "      <td>0.092319</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.387687</td>\n",
       "      <td>0.454388</td>\n",
       "      <td>-1.721336e-02</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>2.70492</td>\n",
       "      <td>0.354811</td>\n",
       "      <td>0.192590</td>\n",
       "      <td>0.140149</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.381749</td>\n",
       "      <td>0.770822</td>\n",
       "      <td>6.432491e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6939 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pv_output  direct_irradiance  diffuse_irradiance  reflected_irradiance  \\\n",
       "0       0.18438           0.005371            0.065585              0.031635   \n",
       "1       2.55676           0.332888            0.188187              0.137603   \n",
       "2       2.25707           0.287603            0.181857              0.127422   \n",
       "3       2.77577           0.364820            0.198938              0.151992   \n",
       "4       0.08309           0.000897            0.033462              0.015843   \n",
       "...         ...                ...                 ...                   ...   \n",
       "6934    2.03699           0.232890            0.227027              0.130902   \n",
       "6935    1.26006           0.150560            0.133012              0.083684   \n",
       "6936    0.43408           0.028270            0.108200              0.053192   \n",
       "6937    0.28637           0.009971            0.092319              0.044569   \n",
       "6938    2.70492           0.354811            0.192590              0.140149   \n",
       "\n",
       "      sun_height      temp  wind_speed      year_sin  year_cos  \n",
       "0       0.006396  0.365736    0.331266  1.721336e-02  0.999852  \n",
       "1       0.007762  0.318815    0.431817  3.442161e-02  0.999407  \n",
       "2       0.009273  0.290491    0.318518  5.161967e-02  0.998667  \n",
       "3       0.010888  0.251810    0.337021  6.880243e-02  0.997630  \n",
       "4       0.012606  0.356150    0.406667  8.596480e-02  0.996298  \n",
       "...          ...       ...         ...           ...       ...  \n",
       "6934    0.001408  0.391161    0.478298 -6.880243e-02  0.997630  \n",
       "6935    0.002091  0.417086    0.548688 -5.161967e-02  0.998667  \n",
       "6936    0.002877  0.401442    0.559403 -3.442161e-02  0.999407  \n",
       "6937    0.003871  0.387687    0.454388 -1.721336e-02  0.999852  \n",
       "6938    0.004906  0.381749    0.770822  6.432491e-16  1.000000  \n",
       "\n",
       "[6939 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paris.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c8b5ff-ea2a-461c-b07f-8b8c0b6cf415",
   "metadata": {},
   "source": [
    "# Create suitable data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748e8cc-503e-42b7-a903-3f5e698a6095",
   "metadata": {},
   "source": [
    "- separate train and test first (for instance 2/3 for train and 1/3 for test)\n",
    "- then create sequences (2 years x and 1 year y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e8d237-7483-457a-ae3e-06aef10f377a",
   "metadata": {},
   "source": [
    "## Separate train and test datasets\n",
    "- separate train and test first (for instance 2/3 for train and 1/3 for test)\n",
    "- add all train and test dataframes into one dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cdcb7745-e631-4b17-ab68-c1f437d9a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(fold:pd.DataFrame) -> Tuple[pd.DataFrame]:\n",
    "    # Calculate the index for two-thirds of the rows\n",
    "    train_size = int(fold.shape[0] * (2 / 3))\n",
    "\n",
    "    # Create a new DataFrame with the first two-thirds of rows\n",
    "    fold_train = fold.iloc[:train_size]\n",
    "\n",
    "    # Create a new DataFrame with the last third of rows\n",
    "    fold_test = fold.iloc[train_size:]\n",
    "\n",
    "    return (fold_train, fold_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3708b05-d08a-47e1-805b-e38aba9a0f77",
   "metadata": {},
   "source": [
    "## Create sequences (2 years x and 1 year y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2334f684-b1e3-4791-bfe9-f06285c78611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate max index to start a sequence from\n",
    "train_number_sequences = dfs_train_test['paris_train'].shape[0] - 1095\n",
    "test_number_sequences = dfs_train_test['paris_test'].shape[0] - 1095"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af9e2d8-5aba-4746-b027-a7be0d302b98",
   "metadata": {},
   "source": [
    "### Define the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "42ce1846-a127-42f3-ae65-4408dcc8c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y_strides(fold: pd.DataFrame, input_length: int, output_length: int, sequence_stride: int):\n",
    "    '''\n",
    "    - slides through a `fold` Time Series (2D array) to create sequences of equal\n",
    "        * `input_length` for X,\n",
    "        * `output_length` for y,\n",
    "    using a temporal gap `sequence_stride` between each sequence\n",
    "    - returns a list of sequences, each as a 2D-array time series\n",
    "    '''\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(0, len(fold), sequence_stride):\n",
    "        # Exits the loop as soon as the last fold index would exceed the last index\n",
    "        if (i + input_length + output_length) >= len(fold):\n",
    "            break\n",
    "        X_i = fold.iloc[i:i + input_length, :]\n",
    "        y_i = fold.iloc[i + input_length:i + input_length + output_length, :][['pv_output']] # index + length of sequence until index + length of seq. + length of target\n",
    "        X.append(X_i)\n",
    "        y.append(y_i)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab04235-c202-46f4-ac89-e948ae5015c4",
   "metadata": {},
   "source": [
    "### Apply the function to our train folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "564cff79-fed9-4013-bece-e18f355002b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store X_train and y_train for each city\n",
    "X_train_dict = {}\n",
    "y_train_dict = {}\n",
    "\n",
    "# Iterate over each city in train_dfs\n",
    "for city in train_dfs.keys():\n",
    "    # Extract the training DataFrame for the current city\n",
    "    train_df = train_dfs[city]\n",
    "    \n",
    "    # Call the get_X_y_strides function to generate X_train and y_train\n",
    "    X_train, y_train = get_X_y_strides(train_df, input_length=730, output_length=365, sequence_stride=1)\n",
    "    \n",
    "    # Store the results in the dictionaries\n",
    "    X_train_dict[city] = X_train\n",
    "    y_train_dict[city] = y_train\n",
    "\n",
    "# Now X_train_dict and y_train_dict contain the training datasets for each city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bda8fd-1f0a-4350-904f-3f4bc48d83b0",
   "metadata": {},
   "source": [
    "### Apply the function to our test folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2d3f2b6-b631-4467-9f22-45af277662b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store X_test and y_test for each city\n",
    "X_test_dict = {}\n",
    "y_test_dict = {}\n",
    "\n",
    "# Iterate over each city in test_dfs\n",
    "for city in test_dfs.keys():\n",
    "    # Extract the test DataFrame for the current city\n",
    "    test_df = test_dfs[city]\n",
    "    \n",
    "    # Call the get_X_y_strides function to generate X_test and y_test\n",
    "    X_test, y_test = get_X_y_strides(test_df, input_length=730, output_length=365, sequence_stride=1)\n",
    "    \n",
    "    # Store the results in the dictionaries\n",
    "    X_test_dict[city] = X_test\n",
    "    y_test_dict[city] = y_test\n",
    "\n",
    "# Now X_test_dict and y_test_dict contain the testing datasets for each city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1cb0e-dca0-4690-ab92-a7623bb9f5a6",
   "metadata": {},
   "source": [
    "# (2.1) 💻 A Recurrent Neural Network: the `LSTM`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f1ff4e-6e35-43e3-a31c-90c17b268343",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a06dc0b5-f724-40b4-9c9f-777127d1f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(X_train, y_train):\n",
    "    # 1 - RNN architecture\n",
    "    model = models.Sequential()\n",
    "    ## 1.1 - Recurrent Layer\n",
    "    model.add(layers.LSTM(64, \n",
    "                          activation='tanh', \n",
    "                          return_sequences=False,\n",
    "                          kernel_regularizer=L1L2(l1=0.05, l2=0.05),\n",
    "                          input_shape=(X_train.shape[1], X_train.shape[2])  # Specify input shape\n",
    "                          ))\n",
    "    ## 1.2 - Predictive Dense Layers\n",
    "    output_length = y_train.shape[1]\n",
    "    model.add(layers.Dense(output_length, activation='linear'))  \n",
    "\n",
    "    # 2 - Compiler\n",
    "    adam = optimizers.Adam(learning_rate=0.02)    \n",
    "    model.compile(loss='mse', optimizer=adam, metrics=[\"mae\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5bc7fe81-e502-4a8c-bed2-f7ba35ef7990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 64)                18944     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 365)               23725     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,669\n",
      "Trainable params: 42,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = init_model(X_train_dict['paris_train'], y_train_dict['paris_train'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9366d2d-5d94-428d-a027-3308fa0c94b4",
   "metadata": {},
   "source": [
    "## Plot History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bad95593-6f86-4e73-b1ed-9456b2f5de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "    # --- LOSS: MSE --- \n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "    ax[0].set_title('MSE')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].legend(['Train', 'Validation'], loc='best')\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "    \n",
    "    # --- METRICS:MAE ---\n",
    "    \n",
    "    ax[1].plot(history.history['mae'])\n",
    "    ax[1].plot(history.history['val_mae'])\n",
    "    ax[1].set_title('MAE')\n",
    "    ax[1].set_ylabel('MAE')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(['Train', 'Validation'], loc='best')\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "                        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3665e689-05c6-4c21-af99-a9860a31bcd2",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0eee4f2-f6e2-4847-a25c-b4f1a35787a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def fit_model(model: tf.keras.Model, verbose=1) -> Tuple[tf.keras.Model, dict]:\n",
    "\n",
    "    es = EarlyStopping(monitor = \"val_loss\",\n",
    "                      patience = 3,\n",
    "                      mode = \"min\",\n",
    "                      restore_best_weights = True)\n",
    "\n",
    "\n",
    "    history = model.fit(X_train_dict['paris_train'], y_train_dict['paris_train'],\n",
    "                        validation_split = 0.3,\n",
    "                        shuffle = False,     # the order matters!!!\n",
    "                        batch_size = 32,\n",
    "                        epochs = 50,\n",
    "                        callbacks = [es],\n",
    "                        verbose = verbose)\n",
    "\n",
    "    return model, history   # returns a tuple: (model, dict(history))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a2dfb-7753-4d4a-8396-5912f997dede",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Simple LSTM without Cross Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc79dd68-f067-49ac-9dbe-1f5804f42090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 64)                18944     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 365)               23725     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,669\n",
      "Trainable params: 42,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 11:59:36.940622: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 11s 134ms/step - loss: 4.9038 - mae: 1.6630 - val_loss: 3.3683 - val_mae: 1.5026\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 3.6041 - mae: 1.5599 - val_loss: 3.3435 - val_mae: 1.4992\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - 10s 132ms/step - loss: 3.4891 - mae: 1.5347 - val_loss: 3.3221 - val_mae: 1.5000\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - 10s 129ms/step - loss: 3.4514 - mae: 1.5236 - val_loss: 3.3301 - val_mae: 1.4942\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - 10s 130ms/step - loss: 3.4044 - mae: 1.5152 - val_loss: 3.2991 - val_mae: 1.4937\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - 10s 129ms/step - loss: 3.3857 - mae: 1.5106 - val_loss: 3.3144 - val_mae: 1.4937\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - 10s 129ms/step - loss: 3.3734 - mae: 1.5074 - val_loss: 3.3140 - val_mae: 1.4934\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - 10s 129ms/step - loss: 3.3648 - mae: 1.5051 - val_loss: 3.3236 - val_mae: 1.4932\n"
     ]
    }
   ],
   "source": [
    "# 1 - Initialising the RNN model\n",
    "# ====================================\n",
    "\n",
    "model = init_model(X_train_dict['paris_train'], y_train_dict['paris_train'])\n",
    "model.summary()\n",
    "\n",
    "# 2 - Training\n",
    "# ====================================\n",
    "model, history = fit_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc1341-c019-41c0-93f0-e0657d530409",
   "metadata": {},
   "source": [
    "# Create a benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ab734f49-a942-4567-b607-f828c6e307b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda  # Wraps arbitrary expressions as a Layer object\n",
    "\n",
    "def init_baseline():\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    model = models.Sequential() \n",
    "    # a layer to take the last value of the sequence and output it\n",
    "    model.add(layers.Lambda(lambda x: x[:,-1,1,None]))  # all sequences, last day, 1 feature (temperature)\n",
    "    \n",
    "\n",
    "    adam = optimizers.Adam(learning_rate=0.02)\n",
    "    model.compile(loss='mse', optimizer=adam, metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "232438e7-6ea7-46d9-a6af-9692c24a787a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 445us/step - loss: 11.2137 - mae: 2.8608\n",
      "- The Baseline MAE on the test set is equal to 2.86 kwH.\n"
     ]
    }
   ],
   "source": [
    "baseline_model = init_baseline()\n",
    "baseline_score = baseline_model.evaluate(X_test_dict['paris_test'], y_test_dict['paris_test'])\n",
    "print(f\"- The Baseline MAE on the test set is equal to {round(baseline_score[1],2)} kwH.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "def59b17-190b-497d-a101-93cc98bbb2a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- The LSTM MAE on the test set is equal to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[43mres\u001b[49m[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Celsius degrees\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔥 Improvement of the LSTM model over the baseline (on this fold for the test set) = : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m((\u001b[38;5;241m1\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m(res[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39mbaseline_score[\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m % 🔥\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"- The LSTM MAE on the test set is equal to {round(res[1],2)} Celsius degrees\")\n",
    "print(f\"🔥 Improvement of the LSTM model over the baseline (on this fold for the test set) = : {round((1 - (res[1]/baseline_score[1]))*100,2)} % 🔥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef9b698-2caa-47e1-9f9f-20b73eca2d30",
   "metadata": {},
   "source": [
    "## Cross Val LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8dac2ed6-87d1-48c6-a466-edc8356d621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def cross_validate_baseline_and_lstm():\n",
    "    '''\n",
    "    This function cross-validates \n",
    "    - the \"last seen value\" baseline model\n",
    "    - the RNN model\n",
    "    '''\n",
    "\n",
    "    list_of_mae_baseline_model = []\n",
    "    list_of_mae_recurrent_model = []\n",
    "\n",
    "    # 0 - Creating folds\n",
    "    # =========================================  \n",
    "    # Assume you have a dictionary with DataFrames for each city\n",
    "    city_dfs = {\n",
    "        'paris': paris,\n",
    "        'athens': athens,\n",
    "        'berlin': berlin,\n",
    "        'london': london,\n",
    "        'madrid': madrid\n",
    "    }\n",
    "    # Create a list of DataFrames (folds) for each city\n",
    "    folds = [city_dfs[city] for city in city_dfs.keys()]\n",
    "\n",
    "    for fold_id, fold in enumerate(folds):\n",
    "        # 1 - Train/Test split the current fold\n",
    "        # =========================================\n",
    "        (fold_train, fold_test) = train_test_split(fold) # function we coded to split train/test                                 \n",
    "\n",
    "        X_train, y_train = get_X_y_strides(fold_train, input_length=730, output_length=365, sequence_stride=1)  # function we coded to get multiple\n",
    "        X_test, y_test = get_X_y_strides(fold_test, input_length=730, output_length=365, sequence_stride=1)       # sequences from a fold\n",
    "\n",
    "        # 2 - Modelling\n",
    "        # =========================================\n",
    "        \n",
    "        ##### Baseline Model\n",
    "        baseline_model = init_baseline()\n",
    "        mae_baseline = baseline_model.evaluate(X_test, y_test, verbose=0)[1]   # evaluating baseline model (metric)\n",
    "        list_of_mae_baseline_model.append(mae_baseline)\n",
    "        print(\"-\"*50)\n",
    "        print(f\"MAE baseline fold n°{fold_id} = {round(mae_baseline, 2)}\")\n",
    "\n",
    "        ##### LSTM Model\n",
    "        model = init_model(X_train, y_train)\n",
    "        es = EarlyStopping(monitor = 'val_mae',\n",
    "                          mode = \"min\",\n",
    "                           patience = 2, \n",
    "                           restore_best_weights = True)\n",
    "        history = model.fit(X_train, y_train,\n",
    "                           validation_split = 0.3,\n",
    "                           shuffle = False,\n",
    "                           batch_size = 32,\n",
    "                           epochs = 50,\n",
    "                           callbacks = [es],\n",
    "                           verbose = 0)\n",
    "        res = model.evaluate(X_test, y_test, verbose = 0) # evaluating LSTM (metric)\n",
    "        mae_lstm = res[1]\n",
    "        list_of_mae_recurrent_model.append(mae_lstm)\n",
    "        print(f\"MAE LSTM fold n°{fold_id} = {round(mae_lstm, 2)}\")\n",
    "        \n",
    "        ##### Comparison LSTM vs Baseline for the current fold\n",
    "        print(f\"🏋🏽‍♂️ improvement over baseline: {round((1 - (mae_lstm/mae_baseline))*100,2)} % \\n\")\n",
    "\n",
    "    return list_of_mae_baseline_model, list_of_mae_recurrent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6c8071e0-0edf-4239-8e45-ddc2f904e6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "MAE baseline fold n°0 = 2.86\n",
      "MAE LSTM fold n°0 = 1.52\n",
      "🏋🏽‍♂️ improvement over baseline: 46.93 % \n",
      "\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°1 = 3.27\n",
      "MAE LSTM fold n°1 = 1.4\n",
      "🏋🏽‍♂️ improvement over baseline: 57.2 % \n",
      "\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°2 = 2.56\n",
      "MAE LSTM fold n°2 = 1.56\n",
      "🏋🏽‍♂️ improvement over baseline: 39.09 % \n",
      "\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°3 = 2.64\n",
      "MAE LSTM fold n°3 = 1.43\n",
      "🏋🏽‍♂️ improvement over baseline: 45.85 % \n",
      "\n",
      "--------------------------------------------------\n",
      "MAE baseline fold n°4 = 3.79\n",
      "MAE LSTM fold n°4 = 1.2\n",
      "🏋🏽‍♂️ improvement over baseline: 68.41 % \n",
      "\n",
      "CPU times: user 4min 35s, sys: 17 s, total: 4min 52s\n",
      "Wall time: 4min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# WARNING : it takes 75 minutes to run this cell \n",
    "mae_baselines, mae_lstms = cross_validate_baseline_and_lstm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71237a-5cab-461f-8bb6-d5e606ebf0f8",
   "metadata": {},
   "source": [
    "# Create the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ddc759-df8a-41e8-8012-bbacc931c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SEQUENCE A (Paris)\n",
    "\n",
    "day_1 = [10, 25, 60]  # OBSERVATION 1 [temperature, speed, pollution]\n",
    "day_2 = [13, 10, 80]  # OBSERVATION 2 [temperature, speed, pollution]\n",
    "day_3 = [ 9,  5, 90]  # OBSERVATION 3 [temperature, speed, pollution]\n",
    "day_4 = [ 7,  0, 100]  # OBSERVATION 4 [temperature, speed, pollution]\n",
    "\n",
    "sequence_a = [day_1, day_2, day_3, day_4]\n",
    "\n",
    "y_a = [110] # Pollution at day 5\n",
    "\n",
    "# --- SEQUENCE B (Berlin)\n",
    "sequence_b = [[25, 20, 30], [26, 24, 50], [28, 20, 80], [22, 3, 110]]\n",
    "y_b = [125]\n",
    "\n",
    "# --- SEQUENCE C (London)\n",
    "sequence_c = [[15, 10, 60], [25, 20, 65], [35, 10, 75], [36, 15, 70]]\n",
    "y_c = [75]\n",
    "\n",
    "X = np.array([sequence_a, sequence_b, sequence_c]).astype(np.float32)\n",
    "y = np.expand_dims(np.array([y_a, y_b, y_c]).astype(np.float32), axis=-1)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f521a-bd38-4a25-93f2-8fe62d78a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(layers.SimpleRNN(2, return_sequences=True))\n",
    "model_2.add(layers.Dense(1, activation='relu'))\n",
    "model_2.compile(loss='mse', optimizer='adam')\n",
    "model_2.fit(X, y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e14c642-176c-4210-99d3-f3cd07037b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LSTM Model\n",
    "model = init_model(X_train, y_train)\n",
    "es = EarlyStopping(monitor = 'val_mae',\n",
    "                  mode = \"min\",\n",
    "                   patience = 2, \n",
    "                   restore_best_weights = True)\n",
    "history = model.fit(X_train, y_train,\n",
    "                   validation_split = 0.3,\n",
    "                   shuffle = False,\n",
    "                   batch_size = 32,\n",
    "                   epochs = 50,\n",
    "                   callbacks = [es],\n",
    "                   verbose = 0)\n",
    "res = model.evaluate(X_test, y_test, verbose = 0) # evaluating LSTM (metric)\n",
    "mae_lstm = res[1]\n",
    "list_of_mae_recurrent_model.append(mae_lstm)\n",
    "print(f\"MAE LSTM fold n°{fold_id} = {round(mae_lstm, 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
