{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7469640-7da6-48ae-96fb-d3f2502fe0b0",
   "metadata": {},
   "source": [
    "# Using XGBoosting with Preprocessed Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d822eeab-7cca-4c99-822c-305ddb452bfc",
   "metadata": {},
   "source": [
    "## Importing data and creating train, val, test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5aedb1-0b4a-4841-a622-b2f681509469",
   "metadata": {},
   "source": [
    "### Importing preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d5f81a8-7f97-4649-b843-4122cf459919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import make_union\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Reading Raw X_train\n",
    "X_train = pd.read_csv('/Users/niki/code/Niki827/watt_squad/raw_data/train.csv')\n",
    "X_test = pd.read_csv('/Users/niki/code/Niki827/watt_squad/raw_data/test.csv')\n",
    "\n",
    "#Log columns\n",
    "f_logs = [\n",
    "    'precip_1h:mm',\n",
    "    'prob_precip_1h:p',\n",
    "    'clear_sky_rad:W',\n",
    "    'clear_sky_energy_1h:J',\n",
    "    'diffuse_rad:W',\n",
    "    'diffuse_rad_1h:Wh',\n",
    "    'direct_rad:W',\n",
    "    'direct_rad_1h:Wh',\n",
    "    'global_rad:W',\n",
    "    'global_rad_1h:Wh',\n",
    "    'wind_speed_2m:ms',\n",
    "    'wind_speed_10m:ms',\n",
    "    'wind_speed_50m:ms',\n",
    "    'wind_speed_100m:ms'\n",
    "]\n",
    "\n",
    "epsilon = 1e-5\n",
    "\n",
    "for f in f_logs:\n",
    "    X_train[f] = np.log(X_train[f] + epsilon)\n",
    "    X_test[f] = np.log(X_test[f] + epsilon)\n",
    "\n",
    "# Converting time to datetime\n",
    "# We might have done that before already\n",
    "X_train['time']= pd.to_datetime(X_train['time'])\n",
    "X_test['time']= pd.to_datetime(X_test['time'])\n",
    "\n",
    "#the following two steps creates new columns to get the input for the sine & cosine columns\n",
    "#creating columns indicating the hour and the month\n",
    "X_train['hour'] = X_train['time'].dt.hour\n",
    "X_train['month'] = X_train['time'].dt.month\n",
    "\n",
    "X_test['hour'] = X_test['time'].dt.hour\n",
    "X_test['month'] = X_test['time'].dt.month\n",
    "\n",
    "#creating column indicating the season\n",
    "def assign_season(month):\n",
    "    if month in [3, 4, 5]:\n",
    "        return 1  # Spring\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 2  # Summer\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 3  # Fall\n",
    "    else:  # December, January, February\n",
    "        return 4  # Winter\n",
    "\n",
    "# X_train\n",
    "X_train['season'] = X_train['month'].apply(assign_season)\n",
    "\n",
    "X_train['hour_sine'] = np.sin(2 * np.pi * X_train['hour'] / 24)\n",
    "X_train['hour_cosine'] = np.cos(2 * np.pi * X_train['hour'] / 24)\n",
    "\n",
    "X_train['month_sine'] = np.sin(2 * np.pi * X_train['month'] / 12)\n",
    "X_train['month_cosine'] = np.cos(2 * np.pi * X_train['month'] / 12)\n",
    "\n",
    "X_train['season_sine'] = np.sin(2 * np.pi * X_train['season'] / 4)\n",
    "X_train['season_cosine'] = np.cos(2 * np.pi * X_train['season'] / 4)\n",
    "\n",
    "X_train = X_train.drop(columns = ['hour', 'month', 'season'])\n",
    "\n",
    "# X_test\n",
    "X_test['season'] = X_test['month'].apply(assign_season)\n",
    "\n",
    "X_test['hour_sine'] = np.sin(2 * np.pi * X_test['hour'] / 24)\n",
    "X_test['hour_cosine'] = np.cos(2 * np.pi * X_test['hour'] / 24)\n",
    "\n",
    "X_test['month_sine'] = np.sin(2 * np.pi * X_test['month'] / 12)\n",
    "X_test['month_cosine'] = np.cos(2 * np.pi * X_test['month'] / 12)\n",
    "\n",
    "X_test['season_sine'] = np.sin(2 * np.pi * X_test['season'] / 4)\n",
    "X_test['season_cosine'] = np.cos(2 * np.pi * X_test['season'] / 4)\n",
    "\n",
    "X_test = X_test.drop(columns = ['hour', 'month', 'season'])\n",
    "\n",
    "# Cyclic features\n",
    "cyclical_features = ['sun_azimuth:d', 'wind_dir_2m:d', 'wind_dir_10m:d', 'wind_dir_50m:d', 'wind_dir_100m:d']\n",
    "degrees = 360\n",
    "\n",
    "for cyclical_feature in cyclical_features:\n",
    "    sin_column_name = f'sin_{cyclical_feature}'\n",
    "    cos_column_name = f'cos_{cyclical_feature}'\n",
    "    X_train[sin_column_name] = np.sin(2 * np.pi * X_train[cyclical_feature]/2)\n",
    "    X_train[cos_column_name] = np.cos(2 * np.pi * X_train[cyclical_feature]/degrees)\n",
    "    X_test[sin_column_name] = np.sin(2 * np.pi * X_test[cyclical_feature]/2)\n",
    "    X_test[cos_column_name] = np.cos(2 * np.pi * X_test[cyclical_feature]/degrees)\n",
    "\n",
    "X_train = X_train.drop(columns=cyclical_features)\n",
    "X_test = X_test.drop(columns=cyclical_features)\n",
    "\n",
    "# targets = ['pv_production', 'wind_production', 'consumption']\n",
    "f_minmax = [\n",
    "    'hour_sine',\n",
    "    'hour_cosine',\n",
    "    'month_sine',\n",
    "    'month_cosine',\n",
    "    'season_sine',\n",
    "    'season_cosine',\n",
    "    'precip_1h:mm',\n",
    "    'prob_precip_1h:p',\n",
    "    'clear_sky_rad:W',\n",
    "    'clear_sky_energy_1h:J',\n",
    "    'diffuse_rad:W',\n",
    "    'diffuse_rad_1h:Wh',\n",
    "    'direct_rad:W',\n",
    "    'direct_rad_1h:Wh',\n",
    "    'global_rad:W',\n",
    "    'global_rad_1h:Wh',\n",
    "    'sunshine_duration_1h:min',\n",
    "    'low_cloud_cover:p',\n",
    "    'medium_cloud_cover:p',\n",
    "    'high_cloud_cover:p',\n",
    "    'total_cloud_cover:p',\n",
    "    'effective_cloud_cover:p',\n",
    "    'sin_sun_azimuth:d',\n",
    "    'cos_sun_azimuth:d',\n",
    "    'sin_wind_dir_2m:d',\n",
    "    'cos_wind_dir_2m:d',\n",
    "    'sin_wind_dir_10m:d',\n",
    "    'cos_wind_dir_10m:d',\n",
    "    'sin_wind_dir_50m:d',\n",
    "    'cos_wind_dir_50m:d',\n",
    "    'sin_wind_dir_100m:d',\n",
    "    'cos_wind_dir_100m:d',\n",
    "    'relative_humidity_2m:p',\n",
    "    'relative_humidity_10m:p',\n",
    "    'relative_humidity_50m:p',\n",
    "    'relative_humidity_100m:p',\n",
    "    'dew_point_2m:C',\n",
    "    'dew_point_10m:C',\n",
    "    'dew_point_50m:C',\n",
    "    'dew_point_100m:C',\n",
    "    'temp'\n",
    "]\n",
    "f_standard = ['sun_elevation:d']\n",
    "f_robust = [\n",
    "    't_10m:C',\n",
    "    't_50m:C',\n",
    "    't_100m:C',\n",
    "    'wind_speed_2m:ms',\n",
    "    'wind_speed_10m:ms',\n",
    "    'wind_speed_50m:ms',\n",
    "    'wind_speed_100m:ms'\n",
    "]\n",
    "\n",
    "f_ohe = ['precip_type:idx']\n",
    "\n",
    "# other = ['spot_market_price']\n",
    "\n",
    "# target\n",
    "y = X_train[['pv_production', 'wind_production', 'consumption']]\n",
    "# features\n",
    "X_train = X_train.drop(columns=['time', 'pv_production', 'wind_production', 'consumption', 'spot_market_price'])\n",
    "X_test = X_test.drop(columns=['time', 'pv_production', 'wind_production', 'consumption', 'spot_market_price'])\n",
    "\n",
    "# Preprocessing Pipeline\n",
    "minmax_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "cat_transformer = OneHotEncoder()\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "preproc_basic = make_column_transformer(\n",
    "    (minmax_scaler, f_minmax ),\n",
    "    (standard_scaler, f_standard),\n",
    "    (robust_scaler, f_robust),\n",
    "    (cat_transformer, f_ohe),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "# Train X\n",
    "X_train_transformed = preproc_basic.fit_transform(X_train)\n",
    "\n",
    "# Adding Column names\n",
    "X_train_transformed = pd.DataFrame(\n",
    "    X_train_transformed,\n",
    "    columns=preproc_basic.get_feature_names_out()\n",
    ")\n",
    "# Test x\n",
    "X_test_transformed = preproc_basic.transform(X_test)\n",
    "# Adding Column names\n",
    "X_test_transformed = pd.DataFrame(\n",
    "    X_test_transformed,\n",
    "    columns=preproc_basic.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57ca447-741d-4108-9347-3409c087abe0",
   "metadata": {},
   "source": [
    "### Creating y_train and y_test for solar production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47de155d-7244-415f-9751-0cf82aefd3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating y_train dataframe\n",
    "y_train = y.copy()['wind_production']\n",
    "\n",
    "# Importing y_test\n",
    "y_test = pd.read_csv('/Users/niki/code/Niki827/watt_squad/raw_data/test.csv')\n",
    "y_test = y_test['wind_production']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053cadd3-131e-40e9-94e7-7bb2541393cf",
   "metadata": {},
   "source": [
    "### Creating X_val and y_val for solar production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c94058ec-57b2-4df0-9b49-0ecdebc03b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use the same function above for the validation set\n",
    "X_train_transformed, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_transformed, y_train, test_size = 0.1, random_state = 42  # val = 10%\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53dee47-04d9-4c6e-b7ce-736e83d65c40",
   "metadata": {},
   "source": [
    "## Building an XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96ff8f32-4533-44b9-8a8e-0e6ac5082382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install Le Wagon Version of XGBoost\n",
    "#pip install xgboost==1.6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db38089-8c41-4347-a400-6c4c94aae4d3",
   "metadata": {},
   "source": [
    "### Building a first version of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d4804b-4f88-468a-be58-e7c42bf0544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:40.17324\tvalidation_1-rmse:40.38804\n",
      "[1]\tvalidation_0-rmse:37.13638\tvalidation_1-rmse:37.89037\n",
      "[2]\tvalidation_0-rmse:34.40502\tvalidation_1-rmse:35.74652\n",
      "[3]\tvalidation_0-rmse:31.98013\tvalidation_1-rmse:33.79231\n",
      "[4]\tvalidation_0-rmse:29.69135\tvalidation_1-rmse:31.99479\n",
      "[5]\tvalidation_0-rmse:27.67654\tvalidation_1-rmse:30.48409\n",
      "[6]\tvalidation_0-rmse:25.80068\tvalidation_1-rmse:29.17100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niki/.pyenv/versions/3.10.6/envs/watt_squad/lib/python3.10/site-packages/xgboost/sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\tvalidation_0-rmse:24.15098\tvalidation_1-rmse:28.01115\n",
      "[8]\tvalidation_0-rmse:22.66269\tvalidation_1-rmse:27.01665\n",
      "[9]\tvalidation_0-rmse:21.28330\tvalidation_1-rmse:26.09714\n",
      "[10]\tvalidation_0-rmse:20.05902\tvalidation_1-rmse:25.41504\n",
      "[11]\tvalidation_0-rmse:18.91859\tvalidation_1-rmse:24.77366\n",
      "[12]\tvalidation_0-rmse:17.84769\tvalidation_1-rmse:24.26360\n",
      "[13]\tvalidation_0-rmse:16.84781\tvalidation_1-rmse:23.80811\n",
      "[14]\tvalidation_0-rmse:15.92871\tvalidation_1-rmse:23.37278\n",
      "[15]\tvalidation_0-rmse:15.14664\tvalidation_1-rmse:23.10759\n",
      "[16]\tvalidation_0-rmse:14.45814\tvalidation_1-rmse:22.79235\n",
      "[17]\tvalidation_0-rmse:13.74536\tvalidation_1-rmse:22.46413\n",
      "[18]\tvalidation_0-rmse:13.00932\tvalidation_1-rmse:22.15129\n",
      "[19]\tvalidation_0-rmse:12.36631\tvalidation_1-rmse:21.98313\n",
      "[20]\tvalidation_0-rmse:11.78683\tvalidation_1-rmse:21.81871\n",
      "[21]\tvalidation_0-rmse:11.26311\tvalidation_1-rmse:21.66547\n",
      "[22]\tvalidation_0-rmse:10.77799\tvalidation_1-rmse:21.47611\n",
      "[23]\tvalidation_0-rmse:10.30046\tvalidation_1-rmse:21.29044\n",
      "[24]\tvalidation_0-rmse:9.88303\tvalidation_1-rmse:21.16507\n",
      "[25]\tvalidation_0-rmse:9.46192\tvalidation_1-rmse:21.04871\n",
      "[26]\tvalidation_0-rmse:9.08408\tvalidation_1-rmse:20.97333\n",
      "[27]\tvalidation_0-rmse:8.74397\tvalidation_1-rmse:20.90335\n",
      "[28]\tvalidation_0-rmse:8.40036\tvalidation_1-rmse:20.87006\n",
      "[29]\tvalidation_0-rmse:8.10828\tvalidation_1-rmse:20.81219\n",
      "[30]\tvalidation_0-rmse:7.84412\tvalidation_1-rmse:20.79558\n",
      "[31]\tvalidation_0-rmse:7.54911\tvalidation_1-rmse:20.74385\n",
      "[32]\tvalidation_0-rmse:7.32166\tvalidation_1-rmse:20.70708\n",
      "[33]\tvalidation_0-rmse:7.09706\tvalidation_1-rmse:20.67919\n",
      "[34]\tvalidation_0-rmse:6.89684\tvalidation_1-rmse:20.66862\n",
      "[35]\tvalidation_0-rmse:6.73270\tvalidation_1-rmse:20.62453\n",
      "[36]\tvalidation_0-rmse:6.54748\tvalidation_1-rmse:20.62127\n",
      "[37]\tvalidation_0-rmse:6.35080\tvalidation_1-rmse:20.59635\n",
      "[38]\tvalidation_0-rmse:6.20314\tvalidation_1-rmse:20.57009\n",
      "[39]\tvalidation_0-rmse:6.06652\tvalidation_1-rmse:20.54235\n",
      "[40]\tvalidation_0-rmse:5.88688\tvalidation_1-rmse:20.50396\n",
      "[41]\tvalidation_0-rmse:5.76105\tvalidation_1-rmse:20.49273\n",
      "[42]\tvalidation_0-rmse:5.65841\tvalidation_1-rmse:20.46750\n",
      "[43]\tvalidation_0-rmse:5.55376\tvalidation_1-rmse:20.46125\n",
      "[44]\tvalidation_0-rmse:5.41914\tvalidation_1-rmse:20.46028\n",
      "[45]\tvalidation_0-rmse:5.31451\tvalidation_1-rmse:20.44518\n",
      "[46]\tvalidation_0-rmse:5.17145\tvalidation_1-rmse:20.42629\n",
      "[47]\tvalidation_0-rmse:5.08785\tvalidation_1-rmse:20.40801\n",
      "[48]\tvalidation_0-rmse:5.00424\tvalidation_1-rmse:20.40313\n",
      "[49]\tvalidation_0-rmse:4.90729\tvalidation_1-rmse:20.40672\n",
      "[50]\tvalidation_0-rmse:4.79558\tvalidation_1-rmse:20.40247\n",
      "[51]\tvalidation_0-rmse:4.71555\tvalidation_1-rmse:20.38917\n",
      "[52]\tvalidation_0-rmse:4.66931\tvalidation_1-rmse:20.38553\n",
      "[53]\tvalidation_0-rmse:4.60076\tvalidation_1-rmse:20.38395\n",
      "[54]\tvalidation_0-rmse:4.56331\tvalidation_1-rmse:20.37639\n",
      "[55]\tvalidation_0-rmse:4.49870\tvalidation_1-rmse:20.37225\n",
      "[56]\tvalidation_0-rmse:4.43918\tvalidation_1-rmse:20.36969\n",
      "[57]\tvalidation_0-rmse:4.36773\tvalidation_1-rmse:20.36656\n",
      "[58]\tvalidation_0-rmse:4.34003\tvalidation_1-rmse:20.35645\n",
      "[59]\tvalidation_0-rmse:4.26850\tvalidation_1-rmse:20.33492\n",
      "[60]\tvalidation_0-rmse:4.20170\tvalidation_1-rmse:20.31421\n",
      "[61]\tvalidation_0-rmse:4.14809\tvalidation_1-rmse:20.30784\n",
      "[62]\tvalidation_0-rmse:4.09420\tvalidation_1-rmse:20.31162\n",
      "[63]\tvalidation_0-rmse:4.04217\tvalidation_1-rmse:20.30031\n",
      "[64]\tvalidation_0-rmse:4.00227\tvalidation_1-rmse:20.29486\n",
      "[65]\tvalidation_0-rmse:3.94497\tvalidation_1-rmse:20.28853\n",
      "[66]\tvalidation_0-rmse:3.92490\tvalidation_1-rmse:20.27961\n",
      "[67]\tvalidation_0-rmse:3.91172\tvalidation_1-rmse:20.27899\n",
      "[68]\tvalidation_0-rmse:3.86698\tvalidation_1-rmse:20.26946\n",
      "[69]\tvalidation_0-rmse:3.85021\tvalidation_1-rmse:20.26142\n",
      "[70]\tvalidation_0-rmse:3.79496\tvalidation_1-rmse:20.24551\n",
      "[71]\tvalidation_0-rmse:3.75213\tvalidation_1-rmse:20.24116\n",
      "[72]\tvalidation_0-rmse:3.71933\tvalidation_1-rmse:20.23867\n",
      "[73]\tvalidation_0-rmse:3.69691\tvalidation_1-rmse:20.22889\n",
      "[74]\tvalidation_0-rmse:3.67041\tvalidation_1-rmse:20.23045\n",
      "[75]\tvalidation_0-rmse:3.63883\tvalidation_1-rmse:20.22468\n",
      "[76]\tvalidation_0-rmse:3.58587\tvalidation_1-rmse:20.22080\n",
      "[77]\tvalidation_0-rmse:3.54950\tvalidation_1-rmse:20.21499\n",
      "[78]\tvalidation_0-rmse:3.54144\tvalidation_1-rmse:20.21255\n",
      "[79]\tvalidation_0-rmse:3.50691\tvalidation_1-rmse:20.21771\n",
      "[80]\tvalidation_0-rmse:3.45215\tvalidation_1-rmse:20.21566\n",
      "[81]\tvalidation_0-rmse:3.42085\tvalidation_1-rmse:20.21874\n",
      "[82]\tvalidation_0-rmse:3.37193\tvalidation_1-rmse:20.21478\n",
      "[83]\tvalidation_0-rmse:3.35089\tvalidation_1-rmse:20.21746\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_reg = XGBRegressor(max_depth=10, n_estimators=100, learning_rate = 0.1)\n",
    "xgb_reg.fit(X_train_transformed, y_train,\n",
    "           # evaluate the loss at each iteration\n",
    "            eval_set = [(X_train_transformed, y_train), (X_val, y_val)],\n",
    "            # stop iterating when eval loss increases 5 times in a row\n",
    "            early_stopping_rounds = 5\n",
    "           )\n",
    "\n",
    "y_pred = xgb_reg.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf76eb-6371-4f74-ad62-e047023c88ab",
   "metadata": {},
   "source": [
    "### Evaluating predictions of the first model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db43f283-097e-462c-b3c9-9e4030df0b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.042127820606378"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_mae = ((abs(y_train-y_train.mean())).mean())\n",
    "baseline_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c809df9-8b33-465d-9c93-1583d0d22551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.840454673655064"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mae = ((abs(y_test-y_pred)).mean())\n",
    "model_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29135d4-0935-4f26-9208-d5aeb9d725a3",
   "metadata": {},
   "source": [
    "### Finding the optimal parameters using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25bfde00-8260-4529-8f3f-0b231b284f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 30\u001b[0m\n\u001b[1;32m     20\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     21\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m xgb_reg,\n\u001b[1;32m     22\u001b[0m     param_grid \u001b[38;5;241m=\u001b[39m param_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Fit the grid search\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Get the best parameters and score\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Parameters: \u001b[39m\u001b[38;5;124m'\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/watt_squad/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/watt_squad/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/watt_squad/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/watt_squad/lib/python3.10/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/watt_squad/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/watt_squad/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/watt_squad/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/watt_squad/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid for GridSearch\n",
    "param_grid = {\n",
    "    \"max_depth\": [8,9,10],            # Reduce options\n",
    "    \"learning_rate\": [0.04, 0.05, 0.06],\n",
    "    \"n_estimators\": [600,700,800],\n",
    "    \"reg_alpha\": [0.01, 0.02, 0.03],\n",
    "    \"reg_lambda\": [5, 8, 10],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.8]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "xgb_reg = XGBRegressor(objective='reg:squarederror', eval_metric=\"mae\", random_state=42)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = xgb_reg,\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'neg_mean_squared_error',\n",
    "    cv = 3,\n",
    "    verbose = 1,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "print('Best Parameters: ', grid_search.best_params_)\n",
    "print('Best Score:', -grid_search.best_score_)\n",
    "\n",
    "# Use the best model to predict\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6688b5dd-fe6c-49a3-9248-0ae23e8bf685",
   "metadata": {},
   "source": [
    "### Evaluating predictions of the grid searched model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca83b81-0c34-4c05-a17f-aabe1b5411a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mae = ((abs(y_train-y_train.mean())).mean())\n",
    "baseline_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bb4546-73f3-4895-9bc3-b095799bbda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mae = ((abs(y_test-y_pred)).mean())\n",
    "model_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b2ccd3-4bca-4005-94d2-1b22b6c9cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b4f8e-c048-4e57-9593-6dd84f7d494c",
   "metadata": {},
   "source": [
    "## Feature importance and correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ae4f0a-3586-44bd-9b40-5ec2db80d4fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Calculating feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15830a56-8607-4d7c-ae9d-f9c395f8ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723fb174-350a-4310-a808-6ee7ed5e1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "importance = model.feature_importances_\n",
    "feature_names = X_train_transformed.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importance})\n",
    "importance_df.sort_values(by='Importance', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241fa847-a437-4217-80d0-938e42403f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d50ea4a-026b-426e-806e-868b1babf121",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e3ff7-ba36-477a-8a2d-ff29a89468f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Creating a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b6699c-28df-4a49-aaaa-cfa3bd5757a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = X_train_transformed.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec3a45-dad6-41c9-98a1-2257b2a7ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f3058-1dc5-4eea-9abf-8620d62b7ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318957b3-35c6-4911-89ce-d252c7e8275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features = set()\n",
    "correlation_threshold = 0.9\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i,j]) > correlation_threshold:\n",
    "            correlated_features.add(correlation_matrix.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb8c9d7-e640-4ad0-b037-ca5befd0e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix[['minmaxscaler__global_rad:W']].sort_values(by='minmaxscaler__global_rad:W', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d1164-c6eb-4299-a9ed-b4faa16109e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c00811-9f32-4d38-b640-7ff3cc51c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "((abs(y_test-y_pred)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304481b5-0f14-48ca-abd0-bd9c25dc6d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "((abs(y_test-y_test.mean())).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc0c748-a817-4412-ab23-4480a1205392",
   "metadata": {},
   "source": [
    "## Plotting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2746ffc4-efcf-489b-aabe-e02526e21c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of the 5 most important features\n",
    "important_features = [\n",
    "    'minmaxscaler__global_rad:W',\n",
    "    'minmaxscaler__direct_rad:W',\n",
    "    'minmaxscaler__cos_sun_azimuth:d',\n",
    "    'minmaxscaler__medium_cloud_cover:p',\n",
    "    'minmaxscaler__prob_precip_1h:p'\n",
    "]\n",
    "\n",
    "# Create a scatterplot for each feature\n",
    "for feature in important_features:\n",
    "    plt.figure(figsize=(6, 4))  # Set figure size\n",
    "    sns.scatterplot(x=X_train_transformed[feature], y=y_train)\n",
    "    plt.title(f\"Scatterplot of {feature} vs y_train\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"y_train\")\n",
    "    #plt.xlim(0.4, None)  # Set the lower limit of the x-axis to 0.4\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
